{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "28cde2716f8d44c2ba4a4c5645bc09d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e058adcc90444fa5bbf4871091bc13f4",
              "IPY_MODEL_c44c86fb36df4a5aa114805c8d99daa3",
              "IPY_MODEL_03a02625f1b74b9ba402a198ab30a66f"
            ],
            "layout": "IPY_MODEL_3e7d5bb3a6c041f8b0694b5e7a554e07"
          }
        },
        "e058adcc90444fa5bbf4871091bc13f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b6e6e9dda64d48b750223b17480b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_6d23c18e8ed94bf7a31da31d58297bea",
            "value": "model.safetensors: 100%"
          }
        },
        "c44c86fb36df4a5aa114805c8d99daa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19fdeb15bbb4474dabb2bcefeb149822",
            "max": 476260560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_742d943d0eaf48e4b94be186fe28ffc8",
            "value": 476260560
          }
        },
        "03a02625f1b74b9ba402a198ab30a66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d076f3e03dc47a4bdcbdfc46513c84d",
            "placeholder": "​",
            "style": "IPY_MODEL_0adffcf9cbe4476eaf22931f51e49d8c",
            "value": " 476M/476M [00:11&lt;00:00, 121MB/s]"
          }
        },
        "3e7d5bb3a6c041f8b0694b5e7a554e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b6e6e9dda64d48b750223b17480b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d23c18e8ed94bf7a31da31d58297bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19fdeb15bbb4474dabb2bcefeb149822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742d943d0eaf48e4b94be186fe28ffc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d076f3e03dc47a4bdcbdfc46513c84d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0adffcf9cbe4476eaf22931f51e49d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab554245dc804677944027b0c477113c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f25c1381793437da923b40f183c75db",
              "IPY_MODEL_a811b9221ac642729b61e088874448fc",
              "IPY_MODEL_68db94ec3c984d18a83a7aa4fe701835"
            ],
            "layout": "IPY_MODEL_cdb5734159d645c4bf66b1a6abcdd9fa"
          }
        },
        "5f25c1381793437da923b40f183c75db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2767fb99ce7546c0a51dfed0c7992ce3",
            "placeholder": "​",
            "style": "IPY_MODEL_c5c52b46e95146bfb9a95d5cdec87d6c",
            "value": "model.safetensors: 100%"
          }
        },
        "a811b9221ac642729b61e088874448fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35a8a61eb2c7434584251a39bc9ffab2",
            "max": 476260560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28320876679d4d9095a51c6853ed0f49",
            "value": 476260560
          }
        },
        "68db94ec3c984d18a83a7aa4fe701835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_157785b92ce64e3bb59013c5e8bd4bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_35f5f0f4307848cc9740289899b4b58a",
            "value": " 476M/476M [00:05&lt;00:00, 129MB/s]"
          }
        },
        "cdb5734159d645c4bf66b1a6abcdd9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2767fb99ce7546c0a51dfed0c7992ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c52b46e95146bfb9a95d5cdec87d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35a8a61eb2c7434584251a39bc9ffab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28320876679d4d9095a51c6853ed0f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "157785b92ce64e3bb59013c5e8bd4bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f5f0f4307848cc9740289899b4b58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9be99dcc55804ff58aacdf45a109da13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f56cb805df14b4f878ae7874683e299",
              "IPY_MODEL_a7cbfe596a1547a9bf57b0c22465c0e9",
              "IPY_MODEL_658a8cc10a30422aa4c1f1421cd5ce8a"
            ],
            "layout": "IPY_MODEL_a85eb4a5c06e47f8953fce3568d481b9"
          }
        },
        "3f56cb805df14b4f878ae7874683e299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb36a9a6cc342b1a0805be4cc4ea0b3",
            "placeholder": "​",
            "style": "IPY_MODEL_e80243ab72104740a00b7557a4a915bd",
            "value": "model.safetensors: 100%"
          }
        },
        "a7cbfe596a1547a9bf57b0c22465c0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46730c3cd24a41e29c0829d69e033491",
            "max": 476260560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29bae857135648ba99ba87b45fbedc4b",
            "value": 476260560
          }
        },
        "658a8cc10a30422aa4c1f1421cd5ce8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f2db9f199049dfa62f54b21da27159",
            "placeholder": "​",
            "style": "IPY_MODEL_0b0e89bfe30947beb7ff1355007c1a65",
            "value": " 476M/476M [00:07&lt;00:00, 39.6MB/s]"
          }
        },
        "a85eb4a5c06e47f8953fce3568d481b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb36a9a6cc342b1a0805be4cc4ea0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80243ab72104740a00b7557a4a915bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46730c3cd24a41e29c0829d69e033491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29bae857135648ba99ba87b45fbedc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60f2db9f199049dfa62f54b21da27159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0e89bfe30947beb7ff1355007c1a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6BHZGYXIPKF",
        "outputId": "cb6be8f6-dce4-4649-97a3-9cc76a880886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Landslide\"\n",
        "\n",
        "TRAIN_ZIP = os.path.join(BASE_DIR, \"train_data.zip\")\n",
        "TEST_ZIP  = os.path.join(BASE_DIR, \"test_data.zip\")\n",
        "\n",
        "TRAIN_CSV = os.path.join(BASE_DIR, \"Train.csv\")\n",
        "TEST_CSV  = os.path.join(BASE_DIR, \"Test.csv\")\n",
        "SUB_CSV   = os.path.join(BASE_DIR, \"SampleSubmission.csv\")\n",
        "\n",
        "EXTRACT_DIR = \"/content/landslide_data\"\n",
        "\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "dNjkX2NgIvFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip(zip_path, out_dir):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(out_dir)\n",
        "\n",
        "unzip(TRAIN_ZIP, EXTRACT_DIR)\n",
        "unzip(TEST_ZIP, EXTRACT_DIR)\n",
        "\n",
        "print(\"Extraction complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDIyszVKI2Td",
        "outputId": "c187d6ad-248c-4797-dd90-65fd1a0e5dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df  = pd.read_csv(TEST_CSV)\n",
        "sub_df   = pd.read_csv(SUB_CSV)\n",
        "\n",
        "print(\"Train CSV shape:\", train_df.shape)\n",
        "print(\"Test CSV shape :\", test_df.shape)\n",
        "print(\"Submission shape:\", sub_df.shape)\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "9BmqLs1kJQg5",
        "outputId": "1e3c71c9-1def-4e7d-f7c7-d83805984ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train CSV shape: (7147, 2)\n",
            "Test CSV shape : (5398, 1)\n",
            "Submission shape: (5398, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID  label\n",
              "0  ID_HUD1ST      1\n",
              "1  ID_KGE2HY      1\n",
              "2  ID_VHV9BL      1\n",
              "3  ID_ZT0VEJ      0\n",
              "4  ID_5NFXVY      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8633708-c97b-4eea-a49a-90a7f2469343\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_HUD1ST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_KGE2HY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_VHV9BL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_ZT0VEJ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_5NFXVY</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8633708-c97b-4eea-a49a-90a7f2469343')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8633708-c97b-4eea-a49a-90a7f2469343 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8633708-c97b-4eea-a49a-90a7f2469343');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2f891f7-17ae-4ffc-bfd7-aa73d77abcf2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2f891f7-17ae-4ffc-bfd7-aa73d77abcf2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2f891f7-17ae-4ffc-bfd7-aa73d77abcf2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7147,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7147,\n        \"samples\": [\n          \"ID_FCQKFO\",\n          \"ID_9WDQCY\",\n          \"ID_AZS6NA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVrAiVkRKChU",
        "outputId": "bacc2a13-a1ff-4bc2-9cb5-108a7ec444ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_col = [c for c in train_df.columns if \"label\" in c.lower() or \"landslide\" in c.lower()][0]\n",
        "\n",
        "train_df[label_col].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "PlPz40GiKHYh",
        "outputId": "8f68806c-e159-4015-f71b-55469fc00e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    5892\n",
              "1    1255\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n"
      ],
      "metadata": {
        "id": "37KLGSndKd2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LandslideDataset(Dataset):\n",
        "    def __init__(self, csv_path, image_dir, is_train=True):\n",
        "        \"\"\"\n",
        "        csv_path : path to Train.csv or Test.csv\n",
        "        image_dir: directory containing .npy files\n",
        "        is_train : whether labels are present\n",
        "        \"\"\"\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_dir = image_dir\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        image_id = row[\"ID\"]\n",
        "        img_path = os.path.join(self.image_dir, image_id + \".npy\")\n",
        "\n",
        "        # Load numpy image\n",
        "        img = np.load(img_path)  # (H, W, C)\n",
        "\n",
        "        # Safety check (paper uses 12 bands)\n",
        "        assert img.ndim == 3, \"Image must be HWC\"\n",
        "        assert img.shape[2] == 12, f\"Expected 12 channels, got {img.shape[2]}\"\n",
        "\n",
        "        # Convert to torch tensor (C, H, W)\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
        "\n",
        "        if self.is_train:\n",
        "            label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "            return img, label\n",
        "        else:\n",
        "            return img, image_id\n"
      ],
      "metadata": {
        "id": "zS20PGnfKL6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_IMG_DIR = \"/content/landslide_data/train\"\n",
        "TEST_IMG_DIR  = \"/content/landslide_data/test\"\n",
        "\n",
        "train_dataset = LandslideDataset(\n",
        "    csv_path=TRAIN_CSV,\n",
        "    image_dir=TRAIN_IMG_DIR,\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "test_dataset = LandslideDataset(\n",
        "    csv_path=TEST_CSV,\n",
        "    image_dir=TEST_IMG_DIR,\n",
        "    is_train=False\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Test samples :\", len(test_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM9mWqSaLFT8",
        "outputId": "a3fbc2ff-7f7f-4147-a14f-73239b83cd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 7147\n",
            "Test samples : 5398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_IMG_DIR = \"/content/landslide_data/train_data\"\n",
        "TEST_IMG_DIR  = \"/content/landslide_data/test_data\"\n"
      ],
      "metadata": {
        "id": "Xte12HLsLOBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LandslideDataset(Dataset):\n",
        "    def __init__(self, csv_path, image_dir, is_train=True):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_dir = image_dir\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        image_id = row[\"ID\"]\n",
        "        img_path = os.path.join(self.image_dir, image_id + \".npy\")\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            raise FileNotFoundError(f\"Missing image: {img_path}\")\n",
        "\n",
        "        # Load image (H, W, C)\n",
        "        img = np.load(img_path)\n",
        "\n",
        "        # Paper requirement: 12 bands\n",
        "        assert img.ndim == 3, \"Expected HWC image\"\n",
        "        assert img.shape[2] == 12, f\"Expected 12 channels, got {img.shape[2]}\"\n",
        "\n",
        "        # Convert to torch tensor (C, H, W)\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
        "\n",
        "        if self.is_train:\n",
        "            label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "            return img, label\n",
        "        else:\n",
        "            return img, image_id\n"
      ],
      "metadata": {
        "id": "ey5_xUtHLnac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LandslideDataset(\n",
        "    csv_path=TRAIN_CSV,\n",
        "    image_dir=TRAIN_IMG_DIR,\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "test_dataset = LandslideDataset(\n",
        "    csv_path=TEST_CSV,\n",
        "    image_dir=TEST_IMG_DIR,\n",
        "    is_train=False\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Test samples :\", len(test_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_GcxNr-LqzV",
        "outputId": "29620a8f-6ffe-42eb-e1d6-51f8bb1b7acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 7147\n",
            "Test samples : 5398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_dataset[0]\n",
        "\n",
        "print(\"Image tensor shape:\", img.shape)\n",
        "print(\"Label:\", label.item())\n",
        "print(\"Min / Max:\", img.min().item(), img.max().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaRaUNlMLtEM",
        "outputId": "8df96328-3d6f-4a3b-b5cc-a723c8932772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image tensor shape: torch.Size([12, 64, 64])\n",
            "Label: 1\n",
            "Min / Max: -50.600467681884766 6372.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from scipy.stats import beta\n"
      ],
      "metadata": {
        "id": "yXdK6ivbMrdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter landslide samples\n",
        "landslide_df = train_dataset.df[train_dataset.df[\"label\"] == 1].reset_index(drop=True)\n",
        "\n",
        "print(\"Original landslide samples:\", len(landslide_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyKtiNBLMtFD",
        "outputId": "c1a8036b-7138-4846-86b8-cd830eab825c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original landslide samples: 1255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "landslide_images = []\n",
        "landslide_ids = []\n",
        "\n",
        "for _, row in tqdm(landslide_df.iterrows(), total=len(landslide_df)):\n",
        "    img_id = row[\"ID\"]\n",
        "    img = np.load(os.path.join(TRAIN_IMG_DIR, img_id + \".npy\"))\n",
        "    landslide_images.append(img)\n",
        "    landslide_ids.append(img_id)\n",
        "\n",
        "landslide_images = np.array(landslide_images)  # (N, H, W, C)\n",
        "\n",
        "print(\"Loaded landslide images:\", landslide_images.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDshvLWSMvFk",
        "outputId": "c2e2ba72-c1eb-4466-fc97-9fe42430f4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1255/1255 [00:07<00:00, 177.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded landslide images: (1255, 64, 64, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multiband_ssim(img1, img2):\n",
        "    ssim_vals = []\n",
        "    for c in range(img1.shape[2]):\n",
        "        ssim_c = ssim(\n",
        "            img1[:, :, c],\n",
        "            img2[:, :, c],\n",
        "            data_range=img1[:, :, c].max() - img1[:, :, c].min()\n",
        "        )\n",
        "        ssim_vals.append(ssim_c)\n",
        "    return np.mean(ssim_vals)\n"
      ],
      "metadata": {
        "id": "2g8ztRypMyai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "neighbors = []\n",
        "\n",
        "print(\"Computing SSIM-based neighbors...\")\n",
        "\n",
        "for i in tqdm(range(len(landslide_images))):\n",
        "    similarities = []\n",
        "    for j in range(len(landslide_images)):\n",
        "        if i == j:\n",
        "            continue\n",
        "        score = multiband_ssim(landslide_images[i], landslide_images[j])\n",
        "        similarities.append((score, j))\n",
        "\n",
        "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
        "    top_k = [idx for _, idx in similarities[:k]]\n",
        "    neighbors.append(top_k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11534YGSM0g9",
        "outputId": "cf2f56a9-ba9c-4f3f-cd43-e1b2ee87143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing SSIM-based neighbors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1255/1255 [3:10:51<00:00,  9.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA = 2\n",
        "BETA = 2\n",
        "LAMBDA_MIN = 0.1\n",
        "LAMBDA_MAX = 0.9\n",
        "\n",
        "NUM_SYNTHETIC = 6275  # paper value\n",
        "\n",
        "synthetic_images = []\n",
        "synthetic_ids = []\n",
        "\n",
        "rng = np.random.default_rng(seed=42)\n",
        "\n",
        "print(\"Generating synthetic images...\")\n",
        "\n",
        "for n in tqdm(range(NUM_SYNTHETIC)):\n",
        "    anchor_idx = rng.integers(0, len(landslide_images))\n",
        "    neighbor_idx = rng.choice(neighbors[anchor_idx])\n",
        "\n",
        "    anchor = landslide_images[anchor_idx]\n",
        "    neighbor = landslide_images[neighbor_idx]\n",
        "\n",
        "    lam = beta.rvs(ALPHA, BETA)\n",
        "    lam = np.clip(lam, LAMBDA_MIN, LAMBDA_MAX)\n",
        "\n",
        "    synthetic = lam * anchor + (1 - lam) * neighbor\n",
        "\n",
        "    syn_id = f\"SMOTE_{n:05d}\"\n",
        "    synthetic_images.append(synthetic.astype(np.float32))\n",
        "    synthetic_ids.append(syn_id)\n"
      ],
      "metadata": {
        "id": "Lg18trX-NP1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fc91ef-8808-49b2-955e-71b288ffeb21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6275/6275 [00:05<00:00, 1083.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SMOTE_DIR = os.path.join(TRAIN_IMG_DIR, \"smote\")\n",
        "os.makedirs(SMOTE_DIR, exist_ok=True)\n",
        "\n",
        "for img, img_id in zip(synthetic_images, synthetic_ids):\n",
        "    np.save(os.path.join(SMOTE_DIR, img_id + \".npy\"), img)\n"
      ],
      "metadata": {
        "id": "ZEh4v9SYVMlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote_df = pd.DataFrame({\n",
        "    \"ID\": synthetic_ids,\n",
        "    \"label\": 1\n",
        "})\n",
        "\n",
        "augmented_train_df = pd.concat(\n",
        "    [train_dataset.df, smote_df],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "print(\"New training size:\", len(augmented_train_df))\n",
        "print(\"New class distribution:\")\n",
        "print(augmented_train_df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "id": "p2voFu_bVOWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUG_TRAIN_CSV = \"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\"\n",
        "augmented_train_df.to_csv(AUG_TRAIN_CSV, index=False)\n",
        "\n",
        "print(\"Saved augmented CSV:\", AUG_TRAIN_CSV)\n"
      ],
      "metadata": {
        "id": "dB4q8JW7VSA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n"
      ],
      "metadata": {
        "id": "Bzt5Hg-rVwhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(labels, num_classes=2):\n",
        "    return F.one_hot(labels, num_classes=num_classes).float()\n"
      ],
      "metadata": {
        "id": "ENtiDb1BVyb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "\n",
        "    batch_size = images.size(0)\n",
        "    index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_images = lam * images + (1 - lam) * images[index]\n",
        "    mixed_labels = lam * labels + (1 - lam) * labels[index]\n",
        "\n",
        "    return mixed_images, mixed_labels\n"
      ],
      "metadata": {
        "id": "yfz4QIapVyON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_bbox(size, lam):\n",
        "    _, _, H, W = size\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return x1, y1, x2, y2\n"
      ],
      "metadata": {
        "id": "WbnzE94PV6k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cutmix(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "\n",
        "    batch_size = images.size(0)\n",
        "    index = torch.randperm(batch_size)\n",
        "\n",
        "    x1, y1, x2, y2 = rand_bbox(images.size(), lam)\n",
        "    images[:, :, y1:y2, x1:x2] = images[index, :, y1:y2, x1:x2]\n",
        "\n",
        "    lam = 1 - ((x2 - x1) * (y2 - y1) / (images.size(-1) * images.size(-2)))\n",
        "    mixed_labels = lam * labels + (1 - lam) * labels[index]\n",
        "\n",
        "    return images, mixed_labels"
      ],
      "metadata": {
        "id": "sxPdedMaWHGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_color_geom_transform(img):\n",
        "    # img: (C, H, W)\n",
        "    if random.random() < 0.5:\n",
        "        img = TF.adjust_brightness(img, brightness_factor=random.uniform(0.8, 1.2))\n",
        "    if random.random() < 0.5:\n",
        "        img = TF.adjust_contrast(img, contrast_factor=random.uniform(0.8, 1.2))\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        angle = random.uniform(-15, 15)\n",
        "        img = TF.rotate(img, angle)\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        img = TF.hflip(img)\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        img = TF.vflip(img)\n",
        "\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "kIXRhEtmWBkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_online_augmentation(images, labels):\n",
        "    # images: (B, C, H, W)\n",
        "    # labels: (B,) hard labels\n",
        "\n",
        "    # Convert to soft labels\n",
        "    labels = one_hot(labels)\n",
        "\n",
        "    # Per-image color & geometry\n",
        "    aug_images = []\n",
        "    for img in images:\n",
        "        aug_images.append(random_color_geom_transform(img))\n",
        "    images = torch.stack(aug_images)\n",
        "\n",
        "    # MixUp or CutMix (random choice)\n",
        "    r = random.random()\n",
        "    if r < 0.5:\n",
        "        images, labels = mixup(images, labels, alpha=1.0)\n",
        "    else:\n",
        "        images, labels = cutmix(images, labels, alpha=1.0)\n",
        "\n",
        "    return images, labels\n"
      ],
      "metadata": {
        "id": "zBotos4BWKHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm\n"
      ],
      "metadata": {
        "id": "jaY0yEvsfUpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n"
      ],
      "metadata": {
        "id": "mkK79tzAfU9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeTo256(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.interpolate(\n",
        "            x, size=(256, 256),\n",
        "            mode=\"bilinear\", align_corners=False\n",
        "        )\n"
      ],
      "metadata": {
        "id": "0xtrOgB5fdJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetV2_Landslide(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resize = ResizeTo256()\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            \"efficientnetv2_l\",\n",
        "            pretrained=True,\n",
        "            num_classes=0  # remove FC\n",
        "        )\n",
        "\n",
        "        # Modify first conv to accept 12 channels\n",
        "        old_conv = self.backbone.conv_stem\n",
        "        self.backbone.conv_stem = nn.Conv2d(\n",
        "            in_channels=12,\n",
        "            out_channels=old_conv.out_channels,\n",
        "            kernel_size=old_conv.kernel_size,\n",
        "            stride=old_conv.stride,\n",
        "            padding=old_conv.padding,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Initialize weights (ImageNet-style)\n",
        "        nn.init.kaiming_normal_(self.backbone.conv_stem.weight)\n",
        "\n",
        "        self.classifier = nn.Linear(\n",
        "            self.backbone.num_features, num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize(x)\n",
        "        features = self.backbone(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits, features\n"
      ],
      "metadata": {
        "id": "CM8HkuZUfnob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_divergence_loss(logits, soft_targets):\n",
        "    log_probs = F.log_softmax(logits, dim=1)\n",
        "    return F.kl_div(log_probs, soft_targets, reduction=\"batchmean\")\n"
      ],
      "metadata": {
        "id": "8EJWu8HKfvpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 36\n",
        "\n",
        "train_smote_dataset = LandslideDataset(\n",
        "    csv_path=AUG_TRAIN_CSV,\n",
        "    image_dir=TRAIN_IMG_DIR,\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_smote_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "rWe4PTWTf0gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "SMOTE_DIR = \"/content/landslide_data/train_data/smote\"\n",
        "\n",
        "files = os.listdir(SMOTE_DIR)\n",
        "print(\"Number of SMOTE files:\", len(files))\n",
        "print(\"Sample files:\", files[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cq-Jye5f2V8",
        "outputId": "b9a712f0-f1e9-44ba-a7ed-3ff17066064a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of SMOTE files: 6275\n",
            "Sample files: ['SMOTE_05531.npy', 'SMOTE_03115.npy', 'SMOTE_01287.npy', 'SMOTE_05098.npy', 'SMOTE_05013.npy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "aug_df = pd.read_csv(\"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\")\n",
        "\n",
        "print(\"Total rows:\", len(aug_df))\n",
        "print(aug_df.tail())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzWwfAwhgAFI",
        "outputId": "8ed32b64-1402-4edc-b0e7-f7a614c35cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows: 13422\n",
            "                ID  label\n",
            "13417  SMOTE_06270      1\n",
            "13418  SMOTE_06271      1\n",
            "13419  SMOTE_06272      1\n",
            "13420  SMOTE_06273      1\n",
            "13421  SMOTE_06274      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find one SMOTE sample\n",
        "smote_row = aug_df[aug_df[\"ID\"].str.startswith(\"SMOTE_\")].iloc[0]\n",
        "print(smote_row)\n",
        "\n",
        "# try loading it\n",
        "smote_img = np.load(\n",
        "    os.path.join(\"/content/landslide_data/train_data/smote\",\n",
        "                 smote_row[\"ID\"] + \".npy\")\n",
        ")\n",
        "\n",
        "print(\"SMOTE image shape:\", smote_img.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9VuG9RW0ULT",
        "outputId": "898cd089-006b-4803-c014-38880f98be53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID       SMOTE_00000\n",
            "label              1\n",
            "Name: 7147, dtype: object\n",
            "SMOTE image shape: (64, 64, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n"
      ],
      "metadata": {
        "id": "BpPFa20I09Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeTo256(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.interpolate(\n",
        "            x, size=(256, 256),\n",
        "            mode=\"bilinear\", align_corners=False\n",
        "        )\n"
      ],
      "metadata": {
        "id": "m6ZbdyWy1LqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetV2_Landslide(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resize = ResizeTo256()\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            \"tf_efficientnetv2_l\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "\n",
        "        old_conv = self.backbone.conv_stem\n",
        "        self.backbone.conv_stem = nn.Conv2d(\n",
        "            in_channels=12,\n",
        "            out_channels=old_conv.out_channels,\n",
        "            kernel_size=old_conv.kernel_size,\n",
        "            stride=old_conv.stride,\n",
        "            padding=old_conv.padding,\n",
        "            bias=False\n",
        "        )\n",
        "        nn.init.kaiming_normal_(self.backbone.conv_stem.weight)\n",
        "\n",
        "        self.classifier = nn.Linear(\n",
        "            self.backbone.num_features, num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize(x)\n",
        "        features = self.backbone(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits, features\n"
      ],
      "metadata": {
        "id": "2WEt6iII1Nm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = EfficientNetV2_Landslide().to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=50\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "28cde2716f8d44c2ba4a4c5645bc09d3",
            "e058adcc90444fa5bbf4871091bc13f4",
            "c44c86fb36df4a5aa114805c8d99daa3",
            "03a02625f1b74b9ba402a198ab30a66f",
            "3e7d5bb3a6c041f8b0694b5e7a554e07",
            "11b6e6e9dda64d48b750223b17480b7e",
            "6d23c18e8ed94bf7a31da31d58297bea",
            "19fdeb15bbb4474dabb2bcefeb149822",
            "742d943d0eaf48e4b94be186fe28ffc8",
            "6d076f3e03dc47a4bdcbdfc46513c84d",
            "0adffcf9cbe4476eaf22931f51e49d8c"
          ]
        },
        "id": "BrtdQ2RO1PnX",
        "outputId": "cd5d547b-f831-4c93-fe95-41599120f7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/476M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28cde2716f8d44c2ba4a4c5645bc09d3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_smote_dataset = LandslideDataset(\n",
        "    csv_path=\"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\",\n",
        "    image_dir=\"/content/landslide_data/train_data\",\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_smote_dataset,\n",
        "    batch_size=36,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "EivaZPuF1SXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LandslideDataset(Dataset):\n",
        "    def __init__(self, csv_path, image_dir, is_train=True):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_dir = image_dir\n",
        "        self.smote_dir = os.path.join(image_dir, \"smote\")\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_id = row[\"ID\"]\n",
        "\n",
        "        # Decide path\n",
        "        if image_id.startswith(\"SMOTE_\"):\n",
        "            img_path = os.path.join(self.smote_dir, image_id + \".npy\")\n",
        "        else:\n",
        "            img_path = os.path.join(self.image_dir, image_id + \".npy\")\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            raise FileNotFoundError(f\"Missing image: {img_path}\")\n",
        "\n",
        "        img = np.load(img_path)\n",
        "\n",
        "        # Safety checks\n",
        "        assert img.ndim == 3, \"Expected HWC image\"\n",
        "        assert img.shape[2] == 12, f\"Expected 12 channels, got {img.shape[2]}\"\n",
        "\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
        "\n",
        "        if self.is_train:\n",
        "            label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "            return img, label\n",
        "        else:\n",
        "            return img, image_id\n"
      ],
      "metadata": {
        "id": "wghhgRzr1WLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_smote_dataset = LandslideDataset(\n",
        "    csv_path=\"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\",\n",
        "    image_dir=\"/content/landslide_data/train_data\",\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_smote_dataset,\n",
        "    batch_size=36,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "TEWjUYgY1qAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_intensity_transform(img):\n",
        "    # img: (C, H, W)\n",
        "    if random.random() < 0.5:\n",
        "        brightness = torch.empty(1).uniform_(0.8, 1.2).item()\n",
        "        img = img * brightness\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        contrast = torch.empty(1).uniform_(0.8, 1.2).item()\n",
        "        mean = img.mean(dim=(1, 2), keepdim=True)\n",
        "        img = (img - mean) * contrast + mean\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        noise = torch.randn_like(img) * 0.01\n",
        "        img = img + noise\n",
        "\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "ecI4MGhd1sOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_geometry_transform(img):\n",
        "    # Horizontal flip\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, dims=[2])\n",
        "\n",
        "    # Vertical flip\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, dims=[1])\n",
        "\n",
        "    # 90-degree rotations\n",
        "    if random.random() < 0.5:\n",
        "        k = random.choice([1, 2, 3])\n",
        "        img = torch.rot90(img, k, dims=[1, 2])\n",
        "\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "E4eZVTyy2E5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_online_augmentation(images, labels):\n",
        "    \"\"\"\n",
        "    images: (B, C, H, W)\n",
        "    labels: (B,)\n",
        "    \"\"\"\n",
        "    # Convert to soft labels\n",
        "    labels = one_hot(labels)\n",
        "\n",
        "    aug_images = []\n",
        "    for img in images:\n",
        "        img = random_intensity_transform(img)\n",
        "        img = random_geometry_transform(img)\n",
        "        aug_images.append(img)\n",
        "\n",
        "    images = torch.stack(aug_images)\n",
        "\n",
        "    # MixUp or CutMix\n",
        "    if random.random() < 0.5:\n",
        "        images, labels = mixup(images, labels, alpha=1.0)\n",
        "    else:\n",
        "        images, labels = cutmix(images, labels, alpha=1.0)\n",
        "\n",
        "    return images, labels\n"
      ],
      "metadata": {
        "id": "-LCbkXrb2Hl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1. Imports\n",
        "# ===============================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# ===============================\n",
        "# 2. Device\n",
        "# ===============================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ===============================\n",
        "# 3. Dataset (FINAL FIXED VERSION)\n",
        "# ===============================\n",
        "class LandslideDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, image_dir, is_train=True):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_dir = image_dir\n",
        "        self.smote_dir = os.path.join(image_dir, \"smote\")\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_id = row[\"ID\"]\n",
        "\n",
        "        if image_id.startswith(\"SMOTE_\"):\n",
        "            img_path = os.path.join(self.smote_dir, image_id + \".npy\")\n",
        "        else:\n",
        "            img_path = os.path.join(self.image_dir, image_id + \".npy\")\n",
        "\n",
        "        img = np.load(img_path)\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
        "\n",
        "        if self.is_train:\n",
        "            return img, torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "        else:\n",
        "            return img, image_id\n",
        "\n",
        "# ===============================\n",
        "# 4. Online Augmentation (SAFE)\n",
        "# ===============================\n",
        "def one_hot(labels, num_classes=2):\n",
        "    return F.one_hot(labels, num_classes).float()\n",
        "\n",
        "def random_intensity_transform(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = img * random.uniform(0.8, 1.2)\n",
        "    if random.random() < 0.5:\n",
        "        mean = img.mean(dim=(1,2), keepdim=True)\n",
        "        img = (img - mean) * random.uniform(0.8, 1.2) + mean\n",
        "    if random.random() < 0.5:\n",
        "        img = img + torch.randn_like(img) * 0.01\n",
        "    return img\n",
        "\n",
        "def random_geometry_transform(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [2])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [1])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.rot90(img, random.choice([1,2,3]), [1,2])\n",
        "    return img\n",
        "\n",
        "def mixup(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(images.size(0))\n",
        "    return lam*images + (1-lam)*images[idx], lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def cutmix(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    B, C, H, W = images.size()\n",
        "    idx = torch.randperm(B)\n",
        "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "    w, h = int(W*np.sqrt(1-lam)), int(H*np.sqrt(1-lam))\n",
        "    x1, x2 = max(cx-w//2,0), min(cx+w//2,W)\n",
        "    y1, y2 = max(cy-h//2,0), min(cy+h//2,H)\n",
        "    images[:, :, y1:y2, x1:x2] = images[idx, :, y1:y2, x1:x2]\n",
        "    lam = 1 - (x2-x1)*(y2-y1)/(H*W)\n",
        "    return images, lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def apply_online_augmentation(images, labels):\n",
        "    labels = one_hot(labels)\n",
        "    imgs = []\n",
        "    for img in images:\n",
        "        img = random_intensity_transform(img)\n",
        "        img = random_geometry_transform(img)\n",
        "        imgs.append(img)\n",
        "    images = torch.stack(imgs)\n",
        "    if random.random() < 0.5:\n",
        "        return mixup(images, labels)\n",
        "    else:\n",
        "        return cutmix(images, labels)\n",
        "\n",
        "# ===============================\n",
        "# 5. Model\n",
        "# ===============================\n",
        "class ResizeTo256(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.interpolate(x, (256,256), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "class EfficientNetV2_Landslide(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resize = ResizeTo256()\n",
        "        self.backbone = timm.create_model(\n",
        "            \"tf_efficientnetv2_l\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "        old = self.backbone.conv_stem\n",
        "        self.backbone.conv_stem = nn.Conv2d(\n",
        "            12, old.out_channels,\n",
        "            kernel_size=old.kernel_size,\n",
        "            stride=old.stride,\n",
        "            padding=old.padding,\n",
        "            bias=False\n",
        "        )\n",
        "        self.classifier = nn.Linear(self.backbone.num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize(x)\n",
        "        f = self.backbone(x)\n",
        "        return self.classifier(f), f\n",
        "\n",
        "# ===============================\n",
        "# 6. Build everything\n",
        "# ===============================\n",
        "model = EfficientNetV2_Landslide().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=3e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
        "\n",
        "train_dataset = LandslideDataset(\n",
        "    \"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\",\n",
        "    \"/content/landslide_data/train_data\",\n",
        "    True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=36, shuffle=True)\n",
        "\n",
        "print(\"✅ Model, dataset, loader READY\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyyaWD5Z2RNN",
        "outputId": "bdfbd066-10e7-4631-901b-8b2f67a2fd9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model, dataset, loader READY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        imgs, soft_labels = apply_online_augmentation(imgs, labels)\n",
        "        soft_labels = soft_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, _ = model(imgs)\n",
        "        loss = F.kl_div(\n",
        "            F.log_softmax(logits, dim=1),\n",
        "            soft_labels,\n",
        "            reduction=\"batchmean\"\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"[Epoch {epoch+1:02d}/50] Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "gHYRyk7i29Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive upload"
      ],
      "metadata": {
        "id": "-m7jiKqE4WE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_BASE = \"/content/drive/MyDrive/Landslide\"\n",
        "DRIVE_DATA = f\"{DRIVE_BASE}/landslide_data\"\n",
        "\n",
        "print(\"Drive base exists:\", DRIVE_BASE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTp5aKzn4VMn",
        "outputId": "f95783a5-5c7f-4c3b-d9f2-7471afc5614d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive base exists: /content/drive/MyDrive/Landslide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/landslide_data /content/drive/MyDrive/Landslide/\n"
      ],
      "metadata": {
        "id": "GdCXDJv84bwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for path in [\n",
        "    f\"{DRIVE_DATA}/train_data\",\n",
        "    f\"{DRIVE_DATA}/train_data/smote\",\n",
        "    f\"{DRIVE_DATA}/test_data\"\n",
        "]:\n",
        "    print(path, \"exists:\", os.path.exists(path),\n",
        "          \"| files:\", len(os.listdir(path)) if os.path.exists(path) else \"N/A\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS8KXDa64eFK",
        "outputId": "b5f87e22-55e3-4f7b-b0b9-b0072afec792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Landslide/landslide_data/train_data exists: True | files: 7148\n",
            "/content/drive/MyDrive/Landslide/landslide_data/train_data/smote exists: True | files: 6275\n",
            "/content/drive/MyDrive/Landslide/landslide_data/test_data exists: True | files: 5397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = f\"{DRIVE_BASE}/Train_SMOTE.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Train_SMOTE.csv shape:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuG_-D0f58_Q",
        "outputId": "08d8962a-75f4-491b-cea9-4ff6285d1a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_SMOTE.csv shape: (13422, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CKPT_DIR = f\"{DRIVE_BASE}/checkpoints\"\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "print(\"Checkpoint dir ready:\", CKPT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-9dIbFG6BBF",
        "outputId": "7bc704c5-097c-45b7-d3e8-f4797c786936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint dir ready: /content/drive/MyDrive/Landslide/checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reset runtime"
      ],
      "metadata": {
        "id": "pF5eFRUI6dxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# 1. Mount Drive\n",
        "# =====================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =====================================\n",
        "# 2. Imports\n",
        "# =====================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 3. Device check\n",
        "# =====================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if device==\"cuda\" else \"None\")\n",
        "\n",
        "# =====================================\n",
        "# 4. Paths (FROM DRIVE ONLY)\n",
        "# =====================================\n",
        "DATA_ROOT = \"/content/drive/MyDrive/Landslide/landslide_data\"\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\"\n",
        "\n",
        "# =====================================\n",
        "# 5. Dataset (FINAL, FIXED)\n",
        "# =====================================\n",
        "class LandslideDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, image_dir, is_train=True):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_dir = image_dir\n",
        "        self.smote_dir = os.path.join(image_dir, \"train_data/smote\")\n",
        "        self.orig_dir = os.path.join(image_dir, \"train_data\")\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_id = row[\"ID\"]\n",
        "\n",
        "        if img_id.startswith(\"SMOTE_\"):\n",
        "            path = os.path.join(self.smote_dir, img_id + \".npy\")\n",
        "        else:\n",
        "            path = os.path.join(self.orig_dir, img_id + \".npy\")\n",
        "\n",
        "        img = np.load(path)\n",
        "        img = torch.from_numpy(img).permute(2,0,1).float()\n",
        "\n",
        "        if self.is_train:\n",
        "            return img, torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "        else:\n",
        "            return img, img_id\n",
        "\n",
        "# =====================================\n",
        "# 6. Online Augmentation (MULTISPECTRAL SAFE)\n",
        "# =====================================\n",
        "def one_hot(labels, num_classes=2):\n",
        "    return F.one_hot(labels, num_classes).float()\n",
        "\n",
        "def random_intensity(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = img * random.uniform(0.8, 1.2)\n",
        "    if random.random() < 0.5:\n",
        "        mean = img.mean(dim=(1,2), keepdim=True)\n",
        "        img = (img - mean) * random.uniform(0.8, 1.2) + mean\n",
        "    if random.random() < 0.5:\n",
        "        img = img + torch.randn_like(img) * 0.01\n",
        "    return img\n",
        "\n",
        "def random_geom(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [2])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [1])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.rot90(img, random.choice([1,2,3]), [1,2])\n",
        "    return img\n",
        "\n",
        "def mixup(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(images.size(0))\n",
        "    return lam*images + (1-lam)*images[idx], lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def cutmix(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    B, C, H, W = images.size()\n",
        "    idx = torch.randperm(B)\n",
        "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "    w, h = int(W*np.sqrt(1-lam)), int(H*np.sqrt(1-lam))\n",
        "    x1, x2 = max(cx-w//2,0), min(cx+w//2,W)\n",
        "    y1, y2 = max(cy-h//2,0), min(cy+h//2,H)\n",
        "    images[:,:,y1:y2,x1:x2] = images[idx,:,y1:y2,x1:x2]\n",
        "    lam = 1 - (x2-x1)*(y2-y1)/(H*W)\n",
        "    return images, lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def apply_aug(images, labels):\n",
        "    labels = one_hot(labels)\n",
        "    imgs = []\n",
        "    for img in images:\n",
        "        img = random_intensity(img)\n",
        "        img = random_geom(img)\n",
        "        imgs.append(img)\n",
        "    images = torch.stack(imgs)\n",
        "    return mixup(images, labels) if random.random()<0.5 else cutmix(images, labels)\n",
        "\n",
        "# =====================================\n",
        "# 7. Model\n",
        "# =====================================\n",
        "class ResizeTo256(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.interpolate(x, (256,256), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "class EfficientNetV2_Landslide(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resize = ResizeTo256()\n",
        "        self.backbone = timm.create_model(\"tf_efficientnetv2_l\", pretrained=True, num_classes=0)\n",
        "        old = self.backbone.conv_stem\n",
        "        self.backbone.conv_stem = nn.Conv2d(\n",
        "            12, old.out_channels,\n",
        "            kernel_size=old.kernel_size,\n",
        "            stride=old.stride,\n",
        "            padding=old.padding,\n",
        "            bias=False\n",
        "        )\n",
        "        self.classifier = nn.Linear(self.backbone.num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize(x)\n",
        "        f = self.backbone(x)\n",
        "        return self.classifier(f), f\n",
        "\n",
        "# =====================================\n",
        "# 8. Build training objects\n",
        "# =====================================\n",
        "model = EfficientNetV2_Landslide().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=3e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
        "\n",
        "train_ds = LandslideDataset(TRAIN_CSV, DATA_ROOT, True)\n",
        "train_loader = DataLoader(train_ds, batch_size=36, shuffle=True, num_workers=0)\n",
        "\n",
        "print(\"✅ Resume setup complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "ab554245dc804677944027b0c477113c",
            "5f25c1381793437da923b40f183c75db",
            "a811b9221ac642729b61e088874448fc",
            "68db94ec3c984d18a83a7aa4fe701835",
            "cdb5734159d645c4bf66b1a6abcdd9fa",
            "2767fb99ce7546c0a51dfed0c7992ce3",
            "c5c52b46e95146bfb9a95d5cdec87d6c",
            "35a8a61eb2c7434584251a39bc9ffab2",
            "28320876679d4d9095a51c6853ed0f49",
            "157785b92ce64e3bb59013c5e8bd4bc0",
            "35f5f0f4307848cc9740289899b4b58a"
          ]
        },
        "id": "DBOVbjHz6gSS",
        "outputId": "339928d9-f5c7-404f-b13d-3a4c73056bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/476M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab554245dc804677944027b0c477113c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Resume setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LandslideDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, data_root, is_train=True):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.data_root = data_root\n",
        "        self.is_train = is_train\n",
        "\n",
        "        self.orig_dir = os.path.join(data_root, \"train_data\")\n",
        "        self.smote_dir = os.path.join(data_root, \"train_data\", \"smote\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_id = row[\"ID\"]\n",
        "\n",
        "        # Try SMOTE first, then original\n",
        "        candidates = [\n",
        "            os.path.join(self.smote_dir, img_id + \".npy\"),\n",
        "            os.path.join(self.orig_dir, img_id + \".npy\"),\n",
        "        ]\n",
        "\n",
        "        for path in candidates:\n",
        "            if os.path.exists(path):\n",
        "                img = np.load(path)\n",
        "                img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
        "                if self.is_train:\n",
        "                    return img, torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "                else:\n",
        "                    return img, img_id\n",
        "\n",
        "        raise FileNotFoundError(f\"Image not found for ID: {img_id}\")\n"
      ],
      "metadata": {
        "id": "DW6M_Da_6oNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = LandslideDataset(\n",
        "    csv_path=\"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\",\n",
        "    data_root=\"/content/drive/MyDrive/Landslide/landslide_data\",\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=36,\n",
        "    shuffle=True,\n",
        "    num_workers=0,   # IMPORTANT for Colab stability\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "print(\"✅ Dataset & DataLoader rebuilt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKdDhh6Z7W96",
        "outputId": "e2dc7b99-e81f-422f-8deb-fc6b11d57854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset & DataLoader rebuilt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_ROOT = \"/content/drive/MyDrive/Landslide/landslide_data\"\n",
        "ORIG_DIR = os.path.join(DATA_ROOT, \"train_data\")\n",
        "SMOTE_DIR = os.path.join(DATA_ROOT, \"train_data\", \"smote\")\n",
        "\n",
        "existing_ids = set()\n",
        "\n",
        "# Original images\n",
        "for f in os.listdir(ORIG_DIR):\n",
        "    if f.endswith(\".npy\"):\n",
        "        existing_ids.add(f.replace(\".npy\", \"\"))\n",
        "\n",
        "# SMOTE images\n",
        "for f in os.listdir(SMOTE_DIR):\n",
        "    if f.endswith(\".npy\"):\n",
        "        existing_ids.add(f.replace(\".npy\", \"\"))\n",
        "\n",
        "print(\"Total existing image IDs:\", len(existing_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obWSeImb7Y6k",
        "outputId": "eef43bf3-f3b8-4415-8082-60ad2267b2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total existing image IDs: 7564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/Landslide/Train_SMOTE.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Original CSV rows:\", len(df))\n",
        "\n",
        "df_clean = df[df[\"ID\"].isin(existing_ids)].reset_index(drop=True)\n",
        "\n",
        "print(\"Clean CSV rows:\", len(df_clean))\n",
        "print(\"Removed rows:\", len(df) - len(df_clean))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWkl_THp7kx3",
        "outputId": "43bc8bdd-a714-464a-f39d-f780b8f21290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original CSV rows: 13422\n",
            "Clean CSV rows: 7564\n",
            "Removed rows: 5858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLEAN_CSV = \"/content/drive/MyDrive/Landslide/Train_SMOTE_CLEAN.csv\"\n",
        "df_clean.to_csv(CLEAN_CSV, index=False)\n",
        "\n",
        "print(\"✅ Clean CSV saved:\", CLEAN_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOvasjTX7mrV",
        "outputId": "f9f1fb72-8e8b-4673-fa02-a2838e9f46f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clean CSV saved: /content/drive/MyDrive/Landslide/Train_SMOTE_CLEAN.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = LandslideDataset(\n",
        "    csv_path=CLEAN_CSV,\n",
        "    data_root=\"/content/drive/MyDrive/Landslide/landslide_data\",\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=36,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "print(\"Dataset size:\", len(train_ds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iwpYI_v7oQy",
        "outputId": "d6059219-2f87-494a-f635-61c490e687ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 7564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = next(iter(train_loader))\n",
        "print(\"Batch OK:\", imgs.shape, labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIoVp7Lw7qjT",
        "outputId": "082002cf-5a08-4898-c00a-68bd2e7000d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch OK: torch.Size([36, 12, 64, 64]) torch.Size([36])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to computational lmits ...changing the batch size yet keeping the same logic"
      ],
      "metadata": {
        "id": "f4cBolTD8LUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# FINAL SAFE TRAINING CELL (COLAB GPU READY)\n",
        "# =========================================================\n",
        "\n",
        "# -----------------\n",
        "# Imports\n",
        "# -----------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# -----------------\n",
        "# Device\n",
        "# -----------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if device==\"cuda\" else \"None\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# -----------------\n",
        "# Paths (FROM DRIVE)\n",
        "# -----------------\n",
        "DATA_ROOT = \"/content/drive/MyDrive/Landslide/landslide_data\"\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/Landslide/Train_SMOTE_CLEAN.csv\"\n",
        "\n",
        "# -----------------\n",
        "# Dataset (ROBUST)\n",
        "# -----------------\n",
        "class LandslideDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, data_root):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.orig_dir = os.path.join(data_root, \"train_data\")\n",
        "        self.smote_dir = os.path.join(data_root, \"train_data\", \"smote\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_id = row[\"ID\"]\n",
        "\n",
        "        candidates = [\n",
        "            os.path.join(self.smote_dir, img_id + \".npy\"),\n",
        "            os.path.join(self.orig_dir, img_id + \".npy\"),\n",
        "        ]\n",
        "\n",
        "        for p in candidates:\n",
        "            if os.path.exists(p):\n",
        "                img = np.load(p)\n",
        "                img = torch.from_numpy(img).permute(2,0,1).float()\n",
        "                return img, torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "\n",
        "        raise FileNotFoundError(img_id)\n",
        "\n",
        "# -----------------\n",
        "# Online Augmentation (MULTISPECTRAL SAFE)\n",
        "# -----------------\n",
        "def one_hot(labels, num_classes=2):\n",
        "    return F.one_hot(labels, num_classes).float()\n",
        "\n",
        "def random_intensity(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = img * random.uniform(0.8, 1.2)\n",
        "    if random.random() < 0.5:\n",
        "        mean = img.mean(dim=(1,2), keepdim=True)\n",
        "        img = (img - mean) * random.uniform(0.8, 1.2) + mean\n",
        "    if random.random() < 0.5:\n",
        "        img = img + torch.randn_like(img) * 0.01\n",
        "    return img\n",
        "\n",
        "def random_geom(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [2])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [1])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.rot90(img, random.choice([1,2,3]), [1,2])\n",
        "    return img\n",
        "\n",
        "def mixup(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(images.size(0))\n",
        "    return lam*images + (1-lam)*images[idx], lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def cutmix(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    B, C, H, W = images.size()\n",
        "    idx = torch.randperm(B)\n",
        "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "    w, h = int(W*np.sqrt(1-lam)), int(H*np.sqrt(1-lam))\n",
        "    x1, x2 = max(cx-w//2,0), min(cx+w//2,W)\n",
        "    y1, y2 = max(cy-h//2,0), min(cy+h//2,H)\n",
        "    images[:,:,y1:y2,x1:x2] = images[idx,:,y1:y2,x1:x2]\n",
        "    lam = 1 - (x2-x1)*(y2-y1)/(H*W)\n",
        "    return images, lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def apply_aug(images, labels):\n",
        "    labels = one_hot(labels)\n",
        "    imgs = []\n",
        "    for img in images:\n",
        "        img = random_intensity(img)\n",
        "        img = random_geom(img)\n",
        "        imgs.append(img)\n",
        "    images = torch.stack(imgs)\n",
        "    return mixup(images, labels) if random.random()<0.5 else cutmix(images, labels)\n",
        "\n",
        "# -----------------\n",
        "# Model\n",
        "# -----------------\n",
        "class ResizeTo256(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.interpolate(x, (256,256), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "class EfficientNetV2_Landslide(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resize = ResizeTo256()\n",
        "        self.backbone = timm.create_model(\n",
        "            \"tf_efficientnetv2_l\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "        old = self.backbone.conv_stem\n",
        "        self.backbone.conv_stem = nn.Conv2d(\n",
        "            12, old.out_channels,\n",
        "            kernel_size=old.kernel_size,\n",
        "            stride=old.stride,\n",
        "            padding=old.padding,\n",
        "            bias=False\n",
        "        )\n",
        "        self.classifier = nn.Linear(self.backbone.num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize(x)\n",
        "        f = self.backbone(x)\n",
        "        return self.classifier(f), f\n",
        "\n",
        "# -----------------\n",
        "# Build Training Objects\n",
        "# -----------------\n",
        "BATCH_SIZE = 8   # OOM-safe\n",
        "EPOCHS = 50\n",
        "\n",
        "train_ds = LandslideDataset(TRAIN_CSV, DATA_ROOT)\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "model = EfficientNetV2_Landslide().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=3e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "print(\"✅ Training setup ready\")\n",
        "\n",
        "# -----------------\n",
        "# Training Loop (AMP ENABLED)\n",
        "# -----------------\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        imgs, soft_labels = apply_aug(imgs, labels)\n",
        "        soft_labels = soft_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits, _ = model(imgs)\n",
        "            loss = F.kl_div(\n",
        "                F.log_softmax(logits, dim=1),\n",
        "                soft_labels,\n",
        "                reduction=\"batchmean\"\n",
        "            )\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"[Epoch {epoch+1:02d}/{EPOCHS}] Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"🎉 TRAINING COMPLETE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "OaC5DZzP75Zq",
        "outputId": "2a7a9faa-9ae2-4c2c-f43c-e879ecde3d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 12666 has 14.74 GiB memory in use. Of the allocated memory 14.52 GiB is allocated by PyTorch, and 98.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1273393656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m )\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEfficientNetV2_Landslide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m                     )\n\u001b[0;32m-> 1357\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1358\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 12666 has 14.74 GiB memory in use. Of the allocated memory 14.52 GiB is allocated by PyTorch, and 98.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again restarting the sesssion"
      ],
      "metadata": {
        "id": "bo2zYecf9IQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# GPU CLEAN START CELL\n",
        "# ===============================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print(\"Free GPU memory (MB):\",\n",
        "      torch.cuda.mem_get_info()[0] // 1024 // 1024)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97JexRRi9L5U",
        "outputId": "b9d01118-4a6f-4480-fc93-b2928eb62b33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Free GPU memory (MB): 14992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# FINAL SAFE TRAINING CELL (COLAB GPU READY)\n",
        "# =========================================================\n",
        "\n",
        "# -----------------\n",
        "# Imports\n",
        "# -----------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# -----------------\n",
        "# Device\n",
        "# -----------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if device==\"cuda\" else \"None\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# -----------------\n",
        "# Paths (FROM DRIVE)\n",
        "# -----------------\n",
        "DATA_ROOT = \"/content/drive/MyDrive/Landslide/landslide_data\"\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/Landslide/Train_SMOTE_CLEAN.csv\"\n",
        "\n",
        "# -----------------\n",
        "# Dataset (ROBUST)\n",
        "# -----------------\n",
        "class LandslideDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, data_root):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.orig_dir = os.path.join(data_root, \"train_data\")\n",
        "        self.smote_dir = os.path.join(data_root, \"train_data\", \"smote\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_id = row[\"ID\"]\n",
        "\n",
        "        candidates = [\n",
        "            os.path.join(self.smote_dir, img_id + \".npy\"),\n",
        "            os.path.join(self.orig_dir, img_id + \".npy\"),\n",
        "        ]\n",
        "\n",
        "        for p in candidates:\n",
        "            if os.path.exists(p):\n",
        "                img = np.load(p)\n",
        "                img = torch.from_numpy(img).permute(2,0,1).float()\n",
        "                return img, torch.tensor(row[\"label\"], dtype=torch.long)\n",
        "\n",
        "        raise FileNotFoundError(img_id)\n",
        "\n",
        "# -----------------\n",
        "# Online Augmentation (MULTISPECTRAL SAFE)\n",
        "# -----------------\n",
        "def one_hot(labels, num_classes=2):\n",
        "    return F.one_hot(labels, num_classes).float()\n",
        "\n",
        "def random_intensity(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = img * random.uniform(0.8, 1.2)\n",
        "    if random.random() < 0.5:\n",
        "        mean = img.mean(dim=(1,2), keepdim=True)\n",
        "        img = (img - mean) * random.uniform(0.8, 1.2) + mean\n",
        "    if random.random() < 0.5:\n",
        "        img = img + torch.randn_like(img) * 0.01\n",
        "    return img\n",
        "\n",
        "def random_geom(img):\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [2])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.flip(img, [1])\n",
        "    if random.random() < 0.5:\n",
        "        img = torch.rot90(img, random.choice([1,2,3]), [1,2])\n",
        "    return img\n",
        "\n",
        "def mixup(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(images.size(0))\n",
        "    return lam*images + (1-lam)*images[idx], lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def cutmix(images, labels, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    B, C, H, W = images.size()\n",
        "    idx = torch.randperm(B)\n",
        "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "    w, h = int(W*np.sqrt(1-lam)), int(H*np.sqrt(1-lam))\n",
        "    x1, x2 = max(cx-w//2,0), min(cx+w//2,W)\n",
        "    y1, y2 = max(cy-h//2,0), min(cy+h//2,H)\n",
        "    images[:,:,y1:y2,x1:x2] = images[idx,:,y1:y2,x1:x2]\n",
        "    lam = 1 - (x2-x1)*(y2-y1)/(H*W)\n",
        "    return images, lam*labels + (1-lam)*labels[idx]\n",
        "\n",
        "def apply_aug(images, labels):\n",
        "    labels = one_hot(labels)\n",
        "    imgs = []\n",
        "    for img in images:\n",
        "        img = random_intensity(img)\n",
        "        img = random_geom(img)\n",
        "        imgs.append(img)\n",
        "    images = torch.stack(imgs)\n",
        "    return mixup(images, labels) if random.random()<0.5 else cutmix(images, labels)\n",
        "\n",
        "# -----------------\n",
        "# Model\n",
        "# -----------------\n",
        "class ResizeTo256(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.interpolate(x, (256,256), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "class EfficientNetV2_Landslide(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resize = ResizeTo256()\n",
        "        self.backbone = timm.create_model(\n",
        "            \"tf_efficientnetv2_l\",\n",
        "            pretrained=True,\n",
        "            num_classes=0\n",
        "        )\n",
        "        old = self.backbone.conv_stem\n",
        "        self.backbone.conv_stem = nn.Conv2d(\n",
        "            12, old.out_channels,\n",
        "            kernel_size=old.kernel_size,\n",
        "            stride=old.stride,\n",
        "            padding=old.padding,\n",
        "            bias=False\n",
        "        )\n",
        "        self.classifier = nn.Linear(self.backbone.num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize(x)\n",
        "        f = self.backbone(x)\n",
        "        return self.classifier(f), f\n",
        "\n",
        "# -----------------\n",
        "# Build Training Objects\n",
        "# -----------------\n",
        "BATCH_SIZE = 8   # OOM-safe\n",
        "EPOCHS = 50\n",
        "\n",
        "train_ds = LandslideDataset(TRAIN_CSV, DATA_ROOT)\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "model = EfficientNetV2_Landslide().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=3e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "print(\"✅ Training setup ready\")\n",
        "\n",
        "# -----------------\n",
        "# Training Loop (AMP ENABLED)\n",
        "# -----------------\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        imgs, soft_labels = apply_aug(imgs, labels)\n",
        "        soft_labels = soft_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits, _ = model(imgs)\n",
        "            loss = F.kl_div(\n",
        "                F.log_softmax(logits, dim=1),\n",
        "                soft_labels,\n",
        "                reduction=\"batchmean\"\n",
        "            )\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"[Epoch {epoch+1:02d}/{EPOCHS}] Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"🎉 TRAINING COMPLETE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "9be99dcc55804ff58aacdf45a109da13",
            "3f56cb805df14b4f878ae7874683e299",
            "a7cbfe596a1547a9bf57b0c22465c0e9",
            "658a8cc10a30422aa4c1f1421cd5ce8a",
            "a85eb4a5c06e47f8953fce3568d481b9",
            "ffb36a9a6cc342b1a0805be4cc4ea0b3",
            "e80243ab72104740a00b7557a4a915bd",
            "46730c3cd24a41e29c0829d69e033491",
            "29bae857135648ba99ba87b45fbedc4b",
            "60f2db9f199049dfa62f54b21da27159",
            "0b0e89bfe30947beb7ff1355007c1a65"
          ]
        },
        "id": "KAvWNGg79S8p",
        "outputId": "c7f4149e-41b4-4713-b97d-320906e9989c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/476M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9be99dcc55804ff58aacdf45a109da13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1273393656.py:166: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training setup ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1273393656.py:185: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# SAVE MODEL, METRICS, AND GRAPHS (ALL FORMATS)\n",
        "# =====================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# -----------------------\n",
        "# Paths\n",
        "# -----------------------\n",
        "SAVE_DIR = \"/content/drive/MyDrive/Landslide/final_outputs\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# -----------------------\n",
        "# 1. SAVE MODEL WEIGHTS\n",
        "# -----------------------\n",
        "\n",
        "# PyTorch native\n",
        "torch.save(model.state_dict(), f\"{SAVE_DIR}/efficientnetv2_landslide.pth\")\n",
        "\n",
        "# Full model (picklable)\n",
        "torch.save(model, f\"{SAVE_DIR}/efficientnetv2_landslide_full.pt\")\n",
        "\n",
        "# TorchScript\n",
        "scripted = torch.jit.script(model)\n",
        "scripted.save(f\"{SAVE_DIR}/efficientnetv2_landslide_scripted.pt\")\n",
        "\n",
        "print(\"✅ Model saved in .pth, .pt, TorchScript formats\")\n",
        "\n",
        "# -----------------------\n",
        "# 2. EXPORT TO H5 (Keras-style container)\n",
        "# -----------------------\n",
        "# Save weights as numpy → H5 container\n",
        "import h5py\n",
        "\n",
        "with h5py.File(f\"{SAVE_DIR}/efficientnetv2_landslide_weights.h5\", \"w\") as f:\n",
        "    for k, v in model.state_dict().items():\n",
        "        f.create_dataset(k, data=v.cpu().numpy())\n",
        "\n",
        "print(\"✅ Model weights saved in .h5 format\")\n",
        "\n",
        "# -----------------------\n",
        "# 3. EVALUATION METRICS (TRAIN SET)\n",
        "# -----------------------\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "eval_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in eval_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        logits, _ = model(imgs)\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "f1  = f1_score(all_labels, all_preds)\n",
        "prec = precision_score(all_labels, all_preds)\n",
        "rec  = recall_score(all_labels, all_preds)\n",
        "\n",
        "metrics = {\n",
        "    \"accuracy\": acc,\n",
        "    \"f1_score\": f1,\n",
        "    \"precision\": prec,\n",
        "    \"recall\": rec\n",
        "}\n",
        "\n",
        "pd.DataFrame([metrics]).to_csv(f\"{SAVE_DIR}/metrics.csv\", index=False)\n",
        "\n",
        "print(\"✅ Metrics saved:\", metrics)\n",
        "\n",
        "# -----------------------\n",
        "# 4. SAVE METRICS AS TEXT\n",
        "# -----------------------\n",
        "with open(f\"{SAVE_DIR}/metrics.txt\", \"w\") as f:\n",
        "    for k, v in metrics.items():\n",
        "        f.write(f\"{k}: {v:.4f}\\n\")\n",
        "\n",
        "# -----------------------\n",
        "# 5. SAVE TRAINING LOSS GRAPH\n",
        "# -----------------------\n",
        "# If you logged loss per epoch, replace this with your loss list\n",
        "# Otherwise, plot dummy placeholder\n",
        "\n",
        "loss_history = []  # OPTIONAL: fill if you logged loss per epoch\n",
        "\n",
        "if len(loss_history) > 0:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(loss_history, label=\"Training Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{SAVE_DIR}/training_loss.png\")\n",
        "    plt.close()\n",
        "else:\n",
        "    with open(f\"{SAVE_DIR}/training_loss.txt\", \"w\") as f:\n",
        "        f.write(\"Loss history not logged during training.\\n\")\n",
        "\n",
        "print(\"✅ Graphs and logs saved\")\n",
        "\n",
        "# -----------------------\n",
        "# 6. FINAL CONFIRMATION\n",
        "# -----------------------\n",
        "print(\"\\n🎉 EVERYTHING SAVED SUCCESSFULLY\")\n",
        "print(\"📂 Location:\", SAVE_DIR)\n"
      ],
      "metadata": {
        "id": "v95mgCjNMagt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}